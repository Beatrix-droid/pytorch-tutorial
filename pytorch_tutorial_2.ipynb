{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGhOUeeLipWguK+InKtyaX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beatrix-droid/pytorch-tutorial/blob/master/pytorch_tutorial_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g92CDjjRqU_m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Learning Pytorch\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "P8a5TFKLqWL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating a tensor"
      ],
      "metadata": {
        "id": "rGhh2mcZwC6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a tensor:\n",
        "import torch\n",
        "\n",
        "x = torch.empty(2,2) # a 2d tensor\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfaHP0_brG9x",
        "outputId": "93d4cbdb-924b-4654-dc43-0b58745eac28"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.9295e-36, 0.0000e+00],\n",
            "        [1.5975e-43, 1.3873e-43]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "can sue teh rand ne==method to create a tensor with random numbers"
      ],
      "metadata": {
        "id": "I03pJgRLryX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#can create tensors from lists as well:\n",
        "torch.tensor([[1., -1.], [1., -1.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGhuMhg-sJIi",
        "outputId": "1a8fc8db-ac10-4d0a-fa14-49f90351b9ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [ 1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#can add tensors as you would normal add ints or concat strings\n",
        "\n",
        "#can also add one tensor to another:\n",
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "y.add_(x) #add tensor x to y. By defualt any function with a trailing underscore in pytorch will be an inplace operation\n",
        "\n",
        "\n",
        "#can also divide and multiplu as one normally woukld"
      ],
      "metadata": {
        "id": "uP8Z-L9ZsRD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting a tensor to a numpy array"
      ],
      "metadata": {
        "id": "LotxgwlNwJs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a=torch.ones(5) #a 1d tensor of len 5 full of ones\n",
        "b = a.numpy() #conver to array\n",
        "print(a)\n",
        "print(type(b))\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgpZNMjRwOm_",
        "outputId": "40c0e7a2-970f-4af3-80da-f92a454f7a48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'numpy.ndarray'>\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting an array to a tensor"
      ],
      "metadata": {
        "id": "ry9L9Zcxxg54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.ones(5) #instantiate the array\n",
        "b=torch.from_numpy(a) #convert the arary to a pytorch tensor\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IocdHmXwk91",
        "outputId": "11a5d98d-4d04-4ce4-c39b-21a4bb59e233"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if you have a cuda toolkit avaialble to do operations on the gpu"
      ],
      "metadata": {
        "id": "FHEe8ZCPyJo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  x= torch.ones(5, device=device)\n",
        "  y=torch.ones(5)\n",
        "  y=y.to(device) #create and move tensors to gpu\n",
        "#if you now try to use numpy n calling  \n",
        "  x.numpy()\n",
        "  #you will get an error because numpy can only handle \n",
        "  #cpu tensors so we would have to move it back to the cpu\n",
        "  x=x.to('cpu')\n",
        "  "
      ],
      "metadata": {
        "id": "W8FYCCUvx01w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad = true\n",
        "when creatinga  tensor in pytorch we can set an optional parameter to True: requires_grad=True  This tells pytorch that it will have to calculate teh gradient of the tensor later on in the computation"
      ],
      "metadata": {
        "id": "WUV-0rbK8BJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad=True)"
      ],
      "metadata": {
        "id": "ADC_dx748AZF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd Pytorch\n",
        "calculate gradients to optimize models"
      ],
      "metadata": {
        "id": "nm_zmOaX8kXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m-mynKU8eIt",
        "outputId": "0602e3a5-0cab-4c04-b780-3505dbcc3c1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0306, 0.8308, 0.6019])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#say we need ot calculate the gradient of a functionat that point.\n",
        "#we set requires_grad=True:\n",
        "x = torch.rand(3, requires_grad=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "b3O_4uRN80k-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now do an operation:\n",
        "y = x+2\n",
        "print(y) #operation was addition so the grad_funct was add\n",
        "z = y*y*2\n",
        "print(z)#operation was mult so the grad_funct was mult\n",
        "z=z.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x_Gxm149QTr",
        "outputId": "14f834dd-8b07-46d8-ae09-a5bf36dc771e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.8129, 2.2352, 2.7104], grad_fn=<AddBackward0>)\n",
            "tensor([15.8252,  9.9925, 14.6929], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now when we want to calculate the gradients the only thing that we need to do is call the .backward() method:"
      ],
      "metadata": {
        "id": "Au3fCgqo_b6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()# will calculate the gradient of z with respect to x so dz/dx"
      ],
      "metadata": {
        "id": "W6OtYGtN_acZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now x has a grad attribute with teh gradients stored that we can use:\n",
        "\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aObXBxBM_v8_",
        "outputId": "8ecd3dc0-fc66-4bc7-93e9-e8c6796d820b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7.5012, 5.9606, 7.2278])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case z was a scalar (as z =z.mean()) so we could just implciitly call the backward function on it.\n",
        "\n",
        "the backward function is based on the chain rule  (jacobain matrix)(vector) = (gradients we are interested in\n",
        "![image info](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "914eY5SIAxq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "in general if z is a vector you need to pass the value f the vector in the function.Say we had something like:\n",
        "```\n",
        "v= torch.tensor([0.1. 1.0, 0.001],dtype=torch.float32)\n",
        "z = y*y*2 #z is now a bector\n",
        "z.backward(v)\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9iJV-1EjAxw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preventing Pytorch from tracking the history\n",
        " (useful when updating weights of a model)\n",
        "\n",
        " We have three options on how to do this:\n",
        " \n",
        " ```\n",
        " 1) x.requres_grad_(False)\n",
        " 2) x.detach()\n",
        " 3) with torch.no_grad():\n",
        " ```"
      ],
      "metadata": {
        "id": "ukH0fUSADq5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#method 1\n",
        "x.requires_grad_(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsV4YrHpDqFf",
        "outputId": "16c250ff-cbb0-4dd7-c4ec-5b37c4d1a985"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8129, 0.2352, 0.7104])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method 2\n",
        "y = x.detach() #creates a new tensor with teh same values but no gradient\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQocqZlWEZyf",
        "outputId": "f8f6f33f-b4d3-493f-df59-771cf6b2266d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8129, 0.2352, 0.7104])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method 3\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EckgFxwGEjYH",
        "outputId": "1612c5e8-9248-45f5-d21d-70db05e5edf4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.8129, 2.2352, 2.7104])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "warning, whenever we call the backward  function then the gradient for the tensors will be accumulated and summed up in the .grad attribute:"
      ],
      "metadata": {
        "id": "9Rywk4QOE3vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(2):\n",
        "  model_output= (weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK9H59LPEyl_",
        "outputId": "6f918945-4c3a-4b47-b835-1032c5c04fdb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for the second one the gradients are incorrect. they have neen usmmed up hence 6\n",
        "\n",
        "#must clear the weights each time:\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(2):\n",
        "  model_output= (weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()#this is the important line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZXELvTMFsKz",
        "outputId": "c8b58a76-fa20-4353-9c7e-a223065a9c9f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    }
  ]
}