{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "P8a5TFKLqWL5",
        "ukH0fUSADq5n",
        "6erKBKjXOa83",
        "0APh2YNzpXiD",
        "2xt_RYsS57P8",
        "k6PY_iURH-aE"
      ],
      "authorship_tag": "ABX9TyPCdRJ5QGodxBkpfZVCXS3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beatrix-droid/pytorch-tutorial/blob/master/pytorch_tutorial_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g92CDjjRqU_m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Learning Pytorch\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "P8a5TFKLqWL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating a tensor"
      ],
      "metadata": {
        "id": "rGhh2mcZwC6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a tensor:\n",
        "import torch\n",
        "\n",
        "x = torch.empty(2,2) # a 2d tensor\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfaHP0_brG9x",
        "outputId": "a218bfad-9afe-405f-db74-008589fe7517"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4153e-34, 0.0000e+00],\n",
            "        [3.3631e-44, 0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "can sue teh rand ne==method to create a tensor with random numbers"
      ],
      "metadata": {
        "id": "I03pJgRLryX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#can create tensors from lists as well:\n",
        "torch.tensor([[1., -1.], [1., -1.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGhuMhg-sJIi",
        "outputId": "1957cccd-c587-4aa0-ba37-efa19ab28e5f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [ 1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#can add tensors as you would normal add ints or concat strings\n",
        "\n",
        "#can also add one tensor to another:\n",
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "y.add_(x) #add tensor x to y. By defualt any function with a trailing underscore in pytorch will be an inplace operation\n",
        "\n",
        "\n",
        "#can also divide and multiplu as one normally woukld"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP8Z-L9ZsRD9",
        "outputId": "17c50b0c-fbd9-4789-84fb-8209cdacb097"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9964, 0.2237],\n",
              "        [0.7131, 0.5633]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting a tensor to a numpy array"
      ],
      "metadata": {
        "id": "LotxgwlNwJs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a=torch.ones(5) #a 1d tensor of len 5 full of ones\n",
        "b = a.numpy() #conver to array\n",
        "print(a)\n",
        "print(type(b))\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgpZNMjRwOm_",
        "outputId": "bce15b81-6444-462c-d395-41b32b7554b2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'numpy.ndarray'>\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting an array to a tensor"
      ],
      "metadata": {
        "id": "ry9L9Zcxxg54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.ones(5) #instantiate the array\n",
        "b=torch.from_numpy(a) #convert the arary to a pytorch tensor\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IocdHmXwk91",
        "outputId": "42ac3067-15c3-4562-c35b-e030b51b09b3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if you have a cuda toolkit avaialble to do operations on the gpu"
      ],
      "metadata": {
        "id": "FHEe8ZCPyJo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  x= torch.ones(5, device=device)\n",
        "  y=torch.ones(5)\n",
        "  y=y.to(device) #create and move tensors to gpu\n",
        "#if you now try to use numpy n calling  \n",
        "  x.numpy()\n",
        "  #you will get an error because numpy can only handle \n",
        "  #cpu tensors so we would have to move it back to the cpu\n",
        "  x=x.to('cpu')\n",
        "  "
      ],
      "metadata": {
        "id": "W8FYCCUvx01w"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad = true\n",
        "when creatinga  tensor in pytorch we can set an optional parameter to True: requires_grad=True  This tells pytorch that it will have to calculate teh gradient of the tensor later on in the computation"
      ],
      "metadata": {
        "id": "WUV-0rbK8BJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad=True)"
      ],
      "metadata": {
        "id": "ADC_dx748AZF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd Pytorch\n",
        "calculate gradients to optimize models"
      ],
      "metadata": {
        "id": "nm_zmOaX8kXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m-mynKU8eIt",
        "outputId": "49dfac5f-a5c6-431a-dad6-78c68d960992"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2644, 0.8070, 0.2173])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#say we need ot calculate the gradient of a functionat that point.\n",
        "#we set requires_grad=True:\n",
        "x = torch.rand(3, requires_grad=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "b3O_4uRN80k-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now do an operation:\n",
        "y = x+2\n",
        "print(y) #operation was addition so the grad_funct was add\n",
        "z = y*y*2\n",
        "print(z)#operation was mult so the grad_funct was mult\n",
        "z=z.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x_Gxm149QTr",
        "outputId": "85ebeddc-d2ed-41f9-ed84-b40950e5fbfb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.6782, 2.7342, 2.3470], grad_fn=<AddBackward0>)\n",
            "tensor([14.3454, 14.9516, 11.0166], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now when we want to calculate the gradients the only thing that we need to do is call the .backward() method:"
      ],
      "metadata": {
        "id": "Au3fCgqo_b6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()# will calculate the gradient of z with respect to x so dz/dx"
      ],
      "metadata": {
        "id": "W6OtYGtN_acZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now x has a grad attribute with teh gradients stored that we can use:\n",
        "\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aObXBxBM_v8_",
        "outputId": "fd190b3c-b11c-4f54-f3fb-f6ea627c83bc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.5709, 3.6456, 3.1293])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case z was a scalar (as z =z.mean()) so we could just implciitly call the backward function on it.\n",
        "\n",
        "the backward function is based on the chain rule  (jacobain matrix)(vector) = (gradients we are interested in\n",
        "![image info](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "914eY5SIAxq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "in general if z is a vector you need to pass the value f the vector in the function.Say we had something like:\n",
        "```\n",
        "v= torch.tensor([0.1. 1.0, 0.001],dtype=torch.float32)\n",
        "z = y*y*2 #z is now a bector\n",
        "z.backward(v)\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9iJV-1EjAxw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preventing Pytorch from tracking the history\n",
        " (useful when updating weights of a model)\n",
        "\n",
        " We have three options on how to do this:\n",
        " \n",
        " ```\n",
        " 1) x.requres_grad_(False)\n",
        " 2) x.detach()\n",
        " 3) with torch.no_grad():\n",
        " ```"
      ],
      "metadata": {
        "id": "ukH0fUSADq5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#method 1\n",
        "x.requires_grad_(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsV4YrHpDqFf",
        "outputId": "b20b7cc6-d386-47e2-86a7-24e91c6a3823"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6782, 0.7342, 0.3470])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method 2\n",
        "y = x.detach() #creates a new tensor with teh same values but no gradient\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQocqZlWEZyf",
        "outputId": "5765e8b2-d78b-4b25-b64e-2fc122e2a792"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6782, 0.7342, 0.3470])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method 3\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EckgFxwGEjYH",
        "outputId": "631223fe-4d54-4164-e688-43be808c7044"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.6782, 2.7342, 2.3470])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "warning, whenever we call the backward  function then the gradient for the tensors will be accumulated and summed up in the .grad attribute:"
      ],
      "metadata": {
        "id": "9Rywk4QOE3vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(2):\n",
        "  model_output= (weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK9H59LPEyl_",
        "outputId": "89b95422-7d4c-47f9-efd9-c799dd2fa28b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for the second one the gradients are incorrect. they have neen usmmed up hence 6\n",
        "\n",
        "#must clear the weights each time:\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(2):\n",
        "  model_output= (weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()#this is the important line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZXELvTMFsKz",
        "outputId": "516e0900-0b2b-4c4f-cbe4-7ab045879b91"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Descent and constructing a basic pipeline for pytorch\n",
        "let's see how to optimize paarameters from scracth by using a linear regression model that we will code from scratch"
      ],
      "metadata": {
        "id": "oCKBegWqvmJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f = w+x\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X=np.array([1,2,3,4], dtype=np.float32)\n",
        "Y=np.array([2,4,6,8], dtype=np.float32)\n",
        "\n",
        "w=0.0"
      ],
      "metadata": {
        "id": "QMNkbEOCvtIi"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "\n",
        "#least square residual loss function\n",
        "def loss(y, y_predicted):\n",
        "  return((y_predicted -y)**2).mean()\n",
        "\n",
        "#gradient\n",
        "#MSE = 1/n *(wx-y)^2 formual for mean squared error\n",
        "#dj/dw = 1/N 2x(wx-y)\n",
        "#implement this fromulka in the gradient: y_predicted= y_predicted\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean() #mean as dividing by n in formula\n"
      ],
      "metadata": {
        "id": "IArJMoQK11q7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"prediction before training: f(5)={forward(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAS6FC1T18KA",
        "outputId": "1b373a2f-3889-4167-9809-cadbd4b1f9c7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: f(5)=0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters=10\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  dw=gradient(X,Y, y_pred)\n",
        "\n",
        "  #update weights\n",
        "  w=w-learning_rate *dw\n",
        "\n",
        "  if epoch % 1 ==0:\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={forward(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0ZNcURJ2L_b",
        "outputId": "62a9b926-e248-4c90-d9b8-b6c7e318ad9e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: W=1.2, loss = 30.0\n",
            "prediction after trainingf(5)=6.0\n",
            "epoch 2: W=1.6799999618530272, loss = 4.799999237060547\n",
            "prediction after trainingf(5)=8.399999809265136\n",
            "epoch 3: W=1.871999988555908, loss = 0.7680001854896545\n",
            "prediction after trainingf(5)=9.35999994277954\n",
            "epoch 4: W=1.9487999868392942, loss = 0.1228799968957901\n",
            "prediction after trainingf(5)=9.743999934196472\n",
            "epoch 5: W=1.9795200133323667, loss = 0.019660834223031998\n",
            "prediction after trainingf(5)=9.897600066661834\n",
            "epoch 6: W=1.9918080282211301, loss = 0.0031457357108592987\n",
            "prediction after trainingf(5)=9.95904014110565\n",
            "epoch 7: W=1.9967231869697568, loss = 0.0005033080233260989\n",
            "prediction after trainingf(5)=9.983615934848784\n",
            "epoch 8: W=1.99868928194046, loss = 8.053186320466921e-05\n",
            "prediction after trainingf(5)=9.993446409702301\n",
            "epoch 9: W=1.999475698471069, loss = 1.2884394891443662e-05\n",
            "prediction after trainingf(5)=9.997378492355345\n",
            "epoch 10: W=1.999790253639221, loss = 2.0613531432900345e-06\n",
            "prediction after trainingf(5)=9.998951268196105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we did the computation of weights manually\n",
        "now lets do the same thing with pytorch. No need for numpy arrays, will use Pytorch tensors"
      ],
      "metadata": {
        "id": "770Ff1_y5QWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X=torch.tensor([1,2,3,4], dtype=torch.float32, requires_grad=True)\n",
        "Y=torch.tensor([2,4,6,8], dtype=torch.float32,  requires_grad=True)\n",
        "w=torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
      ],
      "metadata": {
        "id": "donc5Z5_5MjF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "\n",
        "#least square residual loss function\n",
        "def loss(y, y_predicted):\n",
        "  return((y_predicted -y)**2).mean()\n",
        "\n",
        "#gradient\n",
        "#MSE = 1/n *(wx-y)^2 formual for mean squared error\n",
        "#dj/dw = 1/N 2x(wx-y)\n",
        "#implement this fromulka in the gradient: y_predicted= y_predicted\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean() #mean as dividing by n in formula"
      ],
      "metadata": {
        "id": "cwLWO-sG5rkV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w-= learning_rate * w.grad\n",
        "\n",
        "  w.grad.zero_()  \n",
        "  if epoch % 1 ==0:\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={forward(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaL72pHr9Ru4",
        "outputId": "b33799fe-f515-468c-fca5-811f577c5879"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: W=0.29999998211860657, loss = 30.0\n",
            "prediction after trainingf(5)=1.4999998807907104\n",
            "epoch 2: W=0.5549999475479126, loss = 21.674999237060547\n",
            "prediction after trainingf(5)=2.7749996185302734\n",
            "epoch 3: W=0.7717499136924744, loss = 15.660187721252441\n",
            "prediction after trainingf(5)=3.8587496280670166\n",
            "epoch 4: W=0.9559874534606934, loss = 11.314486503601074\n",
            "prediction after trainingf(5)=4.779937267303467\n",
            "epoch 5: W=1.1125893592834473, loss = 8.17471694946289\n",
            "prediction after trainingf(5)=5.562946796417236\n",
            "epoch 6: W=1.2457009553909302, loss = 5.9062323570251465\n",
            "prediction after trainingf(5)=6.228504657745361\n",
            "epoch 7: W=1.358845829963684, loss = 4.2672529220581055\n",
            "prediction after trainingf(5)=6.794229030609131\n",
            "epoch 8: W=1.4550189971923828, loss = 3.083089828491211\n",
            "prediction after trainingf(5)=7.275094985961914\n",
            "epoch 9: W=1.5367661714553833, loss = 2.227532148361206\n",
            "prediction after trainingf(5)=7.683830738067627\n",
            "epoch 10: W=1.6062512397766113, loss = 1.609391689300537\n",
            "prediction after trainingf(5)=8.031255722045898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "loss=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD([w], lr=learning_rate)"
      ],
      "metadata": {
        "id": "v-5MOpcz_RtY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "replacing the optimizers and the loss function"
      ],
      "metadata": {
        "id": "na7FL5fwKUTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  if epoch % 1 ==0:\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={forward(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X55OaDyUChcw",
        "outputId": "efd7b02b-a853-48a1-bc13-b0a3ae7bdc12"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: W=1.6653136014938354, loss = 1.1627856492996216\n",
            "prediction after trainingf(5)=8.326567649841309\n",
            "epoch 2: W=1.7155165672302246, loss = 0.8401124477386475\n",
            "prediction after trainingf(5)=8.577583312988281\n",
            "epoch 3: W=1.758189082145691, loss = 0.6069811582565308\n",
            "prediction after trainingf(5)=8.790945053100586\n",
            "epoch 4: W=1.7944607734680176, loss = 0.4385439455509186\n",
            "prediction after trainingf(5)=8.97230339050293\n",
            "epoch 5: W=1.825291633605957, loss = 0.3168478012084961\n",
            "prediction after trainingf(5)=9.126458168029785\n",
            "epoch 6: W=1.8514978885650635, loss = 0.22892260551452637\n",
            "prediction after trainingf(5)=9.257489204406738\n",
            "epoch 7: W=1.873773217201233, loss = 0.1653965264558792\n",
            "prediction after trainingf(5)=9.368865966796875\n",
            "epoch 8: W=1.8927072286605835, loss = 0.11949898302555084\n",
            "prediction after trainingf(5)=9.463536262512207\n",
            "epoch 9: W=1.9088011980056763, loss = 0.08633805811405182\n",
            "prediction after trainingf(5)=9.54400634765625\n",
            "epoch 10: W=1.9224810600280762, loss = 0.0623791441321373\n",
            "prediction after trainingf(5)=9.612405776977539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "replacing the forward function"
      ],
      "metadata": {
        "id": "DrIcyLBqKXoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is where we would define the model\n",
        "X=torch.tensor([[1],[2],[3],[4]], dtype=torch.float32, requires_grad=True)\n",
        "Y=torch.tensor([[2],[4],[6],[8]], dtype=torch.float32,  requires_grad=True)\n",
        "X_test= torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "imput_size = n_features\n",
        "output_size = n_features\n",
        "model = nn.Linear(imput_size, output_size)"
      ],
      "metadata": {
        "id": "0Exh-639KMrY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss=nn.MSELoss()\n",
        "#updates the weights\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "PBarsAP9LZZ1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  if epoch % 1 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={model(X_test).item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjVn3fNuLur0",
        "outputId": "bf99934d-8c86-4b97-ae04-07161b7acb6b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: W=Parameter containing:\n",
            "tensor([[-0.0383]], requires_grad=True), loss = 0.0450688973069191\n",
            "prediction after trainingf(5)=-0.46577727794647217\n",
            "epoch 2: W=Parameter containing:\n",
            "tensor([[0.2675]], requires_grad=True), loss = 31.1591796875\n",
            "prediction after trainingf(5)=1.062927484512329\n",
            "epoch 3: W=Parameter containing:\n",
            "tensor([[0.5273]], requires_grad=True), loss = 22.512508392333984\n",
            "prediction after trainingf(5)=2.3623266220092773\n",
            "epoch 4: W=Parameter containing:\n",
            "tensor([[0.7482]], requires_grad=True), loss = 16.26528549194336\n",
            "prediction after trainingf(5)=3.466815948486328\n",
            "epoch 5: W=Parameter containing:\n",
            "tensor([[0.9360]], requires_grad=True), loss = 11.751670837402344\n",
            "prediction after trainingf(5)=4.4056315422058105\n",
            "epoch 6: W=Parameter containing:\n",
            "tensor([[1.0956]], requires_grad=True), loss = 8.490581512451172\n",
            "prediction after trainingf(5)=5.203625202178955\n",
            "epoch 7: W=Parameter containing:\n",
            "tensor([[1.2313]], requires_grad=True), loss = 6.134444713592529\n",
            "prediction after trainingf(5)=5.8819193840026855\n",
            "epoch 8: W=Parameter containing:\n",
            "tensor([[1.3466]], requires_grad=True), loss = 4.432136535644531\n",
            "prediction after trainingf(5)=6.458469867706299\n",
            "epoch 9: W=Parameter containing:\n",
            "tensor([[1.4446]], requires_grad=True), loss = 3.202218532562256\n",
            "prediction after trainingf(5)=6.948537349700928\n",
            "epoch 10: W=Parameter containing:\n",
            "tensor([[1.5279]], requires_grad=True), loss = 2.313603162765503\n",
            "prediction after trainingf(5)=7.365095615386963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "template for creating our custom linear regression model:\n"
      ],
      "metadata": {
        "id": "ixis9skNMTC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  \n",
        "  def __init__(self, imput_dim, ouptut_dim):\n",
        "    super(LinearRegression,self).__init__()\n",
        "    #define layers:\n",
        "    self.lin= nn.Linear(imput_dim, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "YXjEDb5KMShr"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiating an instance of the model:\n",
        "model=LinearRegression(imput_size,output_size)\n",
        "print(f\"Prediction before training f(5)={model(X_test).item()}\")\n",
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  if epoch % 1 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={model(X_test).item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAMJ-KztNEqr",
        "outputId": "c81faf27-30eb-4bb4-b4a1-7ce392569334"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training f(5)=-2.707453727722168\n",
            "epoch 1: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 1.6715781688690186\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 2: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 3: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 4: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 5: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 6: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 7: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 8: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 9: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n",
            "epoch 10: W=Parameter containing:\n",
            "tensor([[-0.6528]], requires_grad=True), loss = 52.778934478759766\n",
            "prediction after trainingf(5)=-2.707453727722168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression in Pytorch"
      ],
      "metadata": {
        "id": "6erKBKjXOa83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typical pytorch pipeline\n",
        "\n",
        "1) design model (input, output size,    forward pass)\n",
        "\n",
        "2) construct loss and optimizer\n",
        "\n",
        "3)training loop\n",
        "\n",
        "4)forward pass: compute prediction and loss\n",
        "\n",
        "5)backward pass: gradients\n",
        "\n",
        "6)update weights\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YsRgH0p7mSnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's look at a more concrete examplem of this:"
      ],
      "metadata": {
        "id": "dZqSQ0G5nJb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "egu17z23mzAF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare data:\n",
        "X_numpy, y_numpy= datasets.make_regression(n_samples=100, n_features=1, \n",
        "                                           noise=20, random_state=1)\n",
        "\n",
        "X=torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y=torch.from_numpy(y_numpy.astype(np.float32))\n",
        "\n",
        "#reshape the tensor:\n",
        "y=y.view(y.shape[0], 1)"
      ],
      "metadata": {
        "id": "bqfYnvBsnRYC"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now that we have preprocessed the data we can proceed with our three steps:\n",
        "\n",
        "     1)step1: design the model"
      ],
      "metadata": {
        "id": "bxoh4FG2oHdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=n_features\n",
        "output_size=1\n",
        "model = nn.Linear(input_size, output_size)"
      ],
      "metadata": {
        "id": "On0GkHN4notK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: define the loss and optimizer functions:"
      ],
      "metadata": {
        "id": "PxPFkiSrozn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "criterion=nn.MSELoss()#in case of linear regression use mean square error function for loss\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "TV2Rf_bpo4Y6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: make the training loop:"
      ],
      "metadata": {
        "id": "DNffD942pXay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass\n",
        "  y_predicted = model(X)\n",
        "  loss=criterion(y_predicted, y)\n",
        "\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  optimizer.step()\n",
        "\n",
        "  #empty gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #print some info every tenth epoch\n",
        "  if (epoch +1)%10 ==0:\n",
        "    print(f\"epoch: {epoch + 1}, loss= {loss.item():.3f}\") #cut at 3 decimal values\n",
        "  \n",
        "\n",
        "#plot values:\n",
        "predicted=model(X).detach().numpy() #must detach as this tensor has gradients set to true\n",
        "plt.plot(X_numpy, y_numpy, \"ro\")\n",
        "plt.plot(X_numpy, predicted,\"b\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "FbW0BdulpcRV",
        "outputId": "144c6415-856e-4d56-ecab-41b7500e476a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss= 4381.914\n",
            "epoch: 20, loss= 3267.416\n",
            "epoch: 30, loss= 2461.665\n",
            "epoch: 40, loss= 1878.474\n",
            "epoch: 50, loss= 1455.929\n",
            "epoch: 60, loss= 1149.481\n",
            "epoch: 70, loss= 927.035\n",
            "epoch: 80, loss= 765.430\n",
            "epoch: 90, loss= 647.937\n",
            "epoch: 100, loss= 562.456\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic regression\n",
        "\n",
        "this is an example of a logistic regression model in pytorch"
      ],
      "metadata": {
        "id": "0APh2YNzpXiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 1) load and prerpare the data"
      ],
      "metadata": {
        "id": "HSfh5m8PxOP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "iEL8xEm9xIHh"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer=datasets.load_breast_cancer()\n",
        "X,y=breast_cancer.data,breast_cancer.target"
      ],
      "metadata": {
        "id": "2SBQkId6xcFx"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_sampless, n_features=X.shape\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "w37e7EFHxsjC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scale data\n",
        "sc = StandardScaler()\n",
        "X_train =sc.fit_transform(X_train)\n",
        "X_test =sc.fit_transform(X_test)\n",
        "\n",
        "# convert to torch tensors:\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))"
      ],
      "metadata": {
        "id": "V3Yy_JkvyBep"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape y\n",
        "y_train = y_train.view(y_train.shape[0],1) #want to make y into a column, vector\n",
        "y_test =y_test.view(y_test.shape[0],1)"
      ],
      "metadata": {
        "id": "3DlToGmCywya"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prepare the model using the logistic regression function"
      ],
      "metadata": {
        "id": "wajD3L4OzHkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "\n",
        "  def __init__(self,input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear=nn.Linear(input_features,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "#instantiate an instance of the model\n",
        "model=LogisticRegression(n_features)"
      ],
      "metadata": {
        "id": "HVBHNmBozM-b"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define optimizer and loss functions"
      ],
      "metadata": {
        "id": "rXDishpg2i1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss() #binary cross entropy\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "hDNsBLCN2Mjp"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main training loop:"
      ],
      "metadata": {
        "id": "QJwGKd6N25FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass\n",
        "  y_predicted=model(X_train)\n",
        "  loss=criterion(y_predicted,y_train)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  #empty weights\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #print info:\n",
        "  if (epoch + 1) %10 ==0:\n",
        "    print(f\"epoch: {epoch + 1}, loss= {loss.item():.3f}\") #cut at 3 decimal values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwr6E56S27fe",
        "outputId": "599a5a96-044d-4b8b-8472-a2a95949f6f6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss= 0.592\n",
            "epoch: 20, loss= 0.481\n",
            "epoch: 30, loss= 0.413\n",
            "epoch: 40, loss= 0.366\n",
            "epoch: 50, loss= 0.332\n",
            "epoch: 60, loss= 0.306\n",
            "epoch: 70, loss= 0.285\n",
            "epoch: 80, loss= 0.268\n",
            "epoch: 90, loss= 0.254\n",
            "epoch: 100, loss= 0.242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate performance of model"
      ],
      "metadata": {
        "id": "iKzRGCPC4HcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()\n",
        "  accuracy=y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
        "  print(f'accuracy: {accuracy: .3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WIaOlOz38me",
        "outputId": "1315d2a6-a432-4d89-c426-97e424f49efe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch Datatests and DataLoader Classes\n",
        "\n",
        "going over some terminology: \n",
        "\n",
        "epoch: 1 forward and backward pass of ALL training samples\n",
        "\n",
        "batch_size: number of training samples in one forward and backward pass\n",
        "\n",
        "number of iterations: number of apsses, each pass using [batch_size] number of samples\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2xt_RYsS57P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import needed modules\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n"
      ],
      "metadata": {
        "id": "_PESv2aO48oM"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "start implementing our own custom dataset:"
      ],
      "metadata": {
        "id": "Hl-q3gsH7TTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy=np.loadtxt('https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv', \n",
        "                  delimiter=',',dtype=np.float32, skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:,1:])\n",
        "    self.y=torch.from_numpy(xy[:,[0]]) #n_samples, 1\n",
        "    self.n_samples =xy.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #allows you to get data by the index\n",
        "    #dataset[0]\n",
        "    return self.x[index], self.y[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    #get len of dataset\n",
        "    return self.n_samples\n",
        "  "
      ],
      "metadata": {
        "id": "Az7oQyvE7W8a"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get dataset:\n",
        "dataset=WineDataset()\n",
        "first_data=dataset[0]\n",
        "features, labels=first_data\n",
        "print(features,labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvk7pEjP-GTs",
        "outputId": "a1c8a93c-4c3d-4d6c-b300-9986a270e6e8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is how we get a dataset. Now let's see how we use a dataloader"
      ],
      "metadata": {
        "id": "7fjViytyA3-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "3EbTz_ZsA3Ir"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter=iter(dataloader)\n",
        "data = dataiter.next()\n",
        "features,labels=data\n",
        "print(features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry-PrdjAAmdD",
        "outputId": "10944b73-5acf-4b46-c509-4beb6c55ad33"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2370e+01, 9.4000e-01, 1.3600e+00, 1.0600e+01, 8.8000e+01, 1.9800e+00,\n",
            "         5.7000e-01, 2.8000e-01, 4.2000e-01, 1.9500e+00, 1.0500e+00, 1.8200e+00,\n",
            "         5.2000e+02],\n",
            "        [1.3390e+01, 1.7700e+00, 2.6200e+00, 1.6100e+01, 9.3000e+01, 2.8500e+00,\n",
            "         2.9400e+00, 3.4000e-01, 1.4500e+00, 4.8000e+00, 9.2000e-01, 3.2200e+00,\n",
            "         1.1950e+03],\n",
            "        [1.3490e+01, 3.5900e+00, 2.1900e+00, 1.9500e+01, 8.8000e+01, 1.6200e+00,\n",
            "         4.8000e-01, 5.8000e-01, 8.8000e-01, 5.7000e+00, 8.1000e-01, 1.8200e+00,\n",
            "         5.8000e+02],\n",
            "        [1.3360e+01, 2.5600e+00, 2.3500e+00, 2.0000e+01, 8.9000e+01, 1.4000e+00,\n",
            "         5.0000e-01, 3.7000e-01, 6.4000e-01, 5.6000e+00, 7.0000e-01, 2.4700e+00,\n",
            "         7.8000e+02]]) tensor([[2.],\n",
            "        [1.],\n",
            "        [3.],\n",
            "        [3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iterate over whole data loader\n",
        "#training loop:\n",
        "num_epochs=2\n",
        "total_samples=len(dataset)\n",
        "n_iterations= math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmdP8qoIBUos",
        "outputId": "08e7468a-df16-4b92-808e-2f8816e55866"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dummy training loop:\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, labels) in enumerate(dataloader):\n",
        "    #forward and backward pass, update weights\n",
        "    if (i+1)%5 ==0:\n",
        "      print(f\"epoch {epoch+1}/{num_epochs}, step{i+1}/{n_iterations},inputs={inputs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrnVTpETF5aK",
        "outputId": "0bf7acb3-3dbc-4758-86d2-b2fffbed9e88"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/2, step5/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step10/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step15/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step20/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step25/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step30/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step35/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step40/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step45/45,inputs=torch.Size([2, 13])\n",
            "epoch 2/2, step5/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step10/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step15/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step20/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step25/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step30/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step35/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step40/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step45/45,inputs=torch.Size([2, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Transforms!\n",
        "\n",
        "we will see how to write a custom class to transform our data\n",
        "\n",
        "Gathering data and code from the previous section, we can skip transforming X and Y in tensors and write separate methods especially for that:\n",
        "\n"
      ],
      "metadata": {
        "id": "k6PY_iURH-aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor:\n",
        "\n",
        "  \"\"\"A class that handles data transformations into tensors\"\"\"\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    \"\"\"This special dunder method makes this a callable object\"\"\"\n",
        "    inputs,targets=sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "aO7QIvfEG7eO"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We need to modify the dataclass to use this transform class.\n",
        "\n",
        "To do this, add a parameter \"transform\" in its init method and eliminate the .from_numpy method:\n"
      ],
      "metadata": {
        "id": "OxWyhVOQLODb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self, transform=None):#added transform parameter\n",
        "    #data loading\n",
        "    xy=np.loadtxt('https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv', \n",
        "                  delimiter=',',dtype=np.float32, skiprows=1)\n",
        "    self.x = xy[:,1:]#modified here\n",
        "    self.y=xy[:,[0]] # and here n_samples, 1\n",
        "    self.n_samples =xy.shape[0]\n",
        "    self.transform=transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #allows you to get data by the index\n",
        "    #dataset[0]\n",
        "    sample=self.x[index], self.y[index] #apply the transformation\n",
        "    if self.transform:\n",
        "      sample=self.transform(sample)\n",
        "      return sample\n",
        "  \n",
        "  def __len__(self):\n",
        "    #get len of dataset\n",
        "    return self.n_samples\n",
        "  "
      ],
      "metadata": {
        "id": "uJOoltslLjZr"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply this transoformation to our dataset\n",
        "dataset = WineDataset(transform=ToTensor())"
      ],
      "metadata": {
        "id": "cNBNs3QMKEMk"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_data=dataset[0]\n",
        "features, labels=first_data\n",
        "print(type(features), type(labels)) #data has been transformed into a tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPUqb_19KKDu",
        "outputId": "fd7612bd-7fc4-4769-d528-37101e0900ac"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = WineDataset(transform=None)\n",
        "first_data=dataset[0]\n",
        "features, labels=first_data\n",
        "print(type(features), type(labels))#if we don't pass this optional parameter our data is still in the shape of a numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "vRu19mOrMtwv",
        "outputId": "4dcfe952-70e8-4828-9451-cc1f4712fafb"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-c889f6fb897b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfirst_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#if we don't pass this optional parameter our data is still in the shape of a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets try implementing a new class:\n"
      ],
      "metadata": {
        "id": "EFZtelFnNZs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MulTransform:\n",
        "  \"\"\"Multiplication transform\"\"\"\n",
        "\n",
        "  def __init__(self, factor):\n",
        "    self.factor=factor\n",
        "\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    \"\"\"This special dunder method makes this a callable object\"\"\"\n",
        "    inputs,target=sample\n",
        "    inputs *= self.factor #multiplication transform\n",
        "    return inputs, target\n",
        "    "
      ],
      "metadata": {
        "id": "k-rWeO8eNJXC"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply this new transform\n",
        "\n",
        "\n",
        "#compose to transforms together by using the compose method and putting them into a list\n",
        "composed= torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "\n",
        "first_data=dataset[0]\n",
        "features, labels=first_data\n",
        "print(type(features), type(labels))\n",
        "print(features)"
      ],
      "metadata": {
        "id": "OjtMQhqFOB6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfa481a-b70e-47f9-a7d8-ca8138a6e1e8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Softmax and crossentropy"
      ],
      "metadata": {
        "id": "tfEC0lvWPp1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "useful concept to preproces images, like turning them into gray scale and preprocessing them"
      ],
      "metadata": {
        "id": "rwno20VKO9Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "\n",
        "x=np.array([2.0,1.0, 0.1])\n",
        "outputs=softmax(x)\n",
        "print('softmax  numpy', outputs)"
      ],
      "metadata": {
        "id": "_g1WMe2yOrN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b260a922-dc32-48f2-9563-51f767060db9"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax  numpy [0.65900114 0.24243297 0.09856589]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs=torch.softmax(x, dim=0)\n",
        "print(outputs)#reuslt is almost the same"
      ],
      "metadata": {
        "id": "DkRWOpaGUCXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(actual, predicted):\n",
        "  loss=-np.sum(actual * np.log(predicted))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "W278yaLlVxM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y must be one hot encoded\n",
        "y=np.array([1,0,0])\n",
        "\n",
        "Y_pred_good=np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad=np.array([0.1, 0.3, 0.6])\n",
        "l1=cross_entropy(y, Y_pred_good)\n",
        "l2=cross_entropy(y, Y_pred_bad)\n",
        "print(f\"Loss1 numpy:{l1: 4f}\")\n",
        "print(f\"Loss2 numpy:{l2: 4f}\")"
      ],
      "metadata": {
        "id": "hznZeqt8We72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets see how we can do this in pytorch"
      ],
      "metadata": {
        "id": "TIEyEA5jnBrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss=nn.CrossEntropyLoss()\n",
        "#Y no softmax in last layer, y_class has labels so no One hot encode!\n",
        "#Y_pred has raw scores (logits) no softmax!"
      ],
      "metadata": {
        "id": "4Jv16FnTnEWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y=torch.tensor([0])\n",
        "#n samples x nlcasses\n",
        "Y_pred_good=torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad=torch.tensor([[0.5, 3.0, 0.3]])"
      ],
      "metadata": {
        "id": "Rf8dbekPrcDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1=loss(Y_pred_good,Y)\n",
        "l2=loss(Y_pred_bad,Y)"
      ],
      "metadata": {
        "id": "ri2buiSjsIMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(l1.item(), l2.item())"
      ],
      "metadata": {
        "id": "roFHK2GlsU7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,predictions1=torch.max(Y_pred_good,1)\n",
        "_,predictions2=torch.max(Y_pred_bad,1)\n",
        "print(predictions1, predictions2)"
      ],
      "metadata": {
        "id": "zMOc7Eu8sXVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple template on how to create an image classifier model with crossentropy:"
      ],
      "metadata": {
        "id": "JwLdROz4t3Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiclass problems:\n",
        "class NeuralNet2(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet2, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2=nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out=self.linear(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    #no softmax at the end\n",
        "    return out\n",
        "\n",
        "model=NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion=nn.CrossEntropyLoss() #applies softmax"
      ],
      "metadata": {
        "id": "oW_BwKJtt_jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Activation functions in Pytorch\n",
        "common activations functions:\n",
        "1)step function\n",
        "\n",
        "2)Sigmoid\n",
        "\n",
        "3)Tanh\n",
        "\n",
        "4)ReLU\n",
        "\n",
        "5)LeakyReLU\n",
        "\n",
        "6)Softmax\n",
        "\n",
        "\n",
        "The stepnfunctions is o for all vlaues of x smaller than 0 and 1 for all vlaues of x greater than 0. It is not used that much in practice:\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/Step_function.svg/1020px-Step_function.svg.png'>\n",
        "\n",
        "\n",
        "The sigmoid (or binary function) used for classification. Is a better version of the step function.\n",
        "The formula is f= 1/(1-e^(-x))\n",
        "\n",
        "It is typically used for binary classification:\n",
        "\n",
        "<img src=\"data:image/png;base64,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\">\n",
        "\n",
        "Next we have the hyperbolic tanh function defined by:\n",
        "f(x) = 2/(1+e^(-2x) -1\n",
        "\n",
        "is basically a scaled and slightly shifted sigmoid function.\n",
        "It will output a value between -1 and 1.It is a good choice of function for the hidden layers:\n",
        "<img src='https://miro.medium.com/max/1190/1*f9erByySVjTjohfFdNkJYQ.jpeg'>\n",
        "\n",
        "\n",
        "the fourht function is the ReLU function. 0 when x is less than 0 and x when x is greater than 0. Is the most popular choice for hidden layers in a network. When you don't know whatto use, just use a ReLU for a hidden layer!\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1200/1*ZafDv3VUm60Eh10OeJu1vw.png\">\n",
        "\n",
        "\n",
        "then we also have the leaky relu. It's a slightly imporved version of the ReLu. It tries to solve the vanishing gradient problem.\n",
        "it is equal to x if x is greater than 0 or a*x if x is less than 0, a being a small positive number.\n",
        "It solves the vaninishing gradient because gby not being 0 after a certain point it ensures that also the gradient is nonzero during the backpropagations step. So it ensures that the weights will be correctly update.\n",
        "\n",
        "Finally we have the Softmax (we have already seen it). It wills quash teh inputs and the outputs to be between 0 and 1.It is typically a good chocie for the last alyer in a MULTI CLASSIFICATION problem"
      ],
      "metadata": {
        "id": "gRGqUbeRwIqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have two options to write the activation layers in our nn model:\n"
      ],
      "metadata": {
        "id": "eULCXCMTMFyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#option one:\n",
        "\n",
        "class Neuralnet(nn.Module):\n",
        "  \n",
        "  \"\"\"for binary classification\"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1 =nn.Linear(input_size, hidden_size)\n",
        "    self.relu==nn.ReLU()\n",
        "    self.linear2 =nn.Linear(hidden_size,1)\n",
        "    self.sigmoid=Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out=self.linear1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    self.sigmoid(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "mywJA99C14Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#option two: Use activation functions direclty in the \n",
        "#forward pass\n",
        "\n",
        "class Neuralnet(nn.Module):\n",
        "  \n",
        "  \"\"\"for binary classification\"\"\"\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    self.linear1 =nn.Linear(input_size, hidden_size)\n",
        "    self.linear2 =nn.Linear(hidden_size,1)\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    out=torch.relu(self.linear1(x)) #call activation functions directly here\n",
        "    out=torch.sigmoid(self.linear2(out))\n",
        "    return out\n",
        "\n",
        "#if some functions aren't directly available in torch use the functional api:\n",
        "#import torch.nn.functional as F  so torch.relu becomes F.leaky_relu()\n"
      ],
      "metadata": {
        "id": "V8pg4C09vCuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feed forward Neural Net\n",
        "Putting everything we have learnt together to create a neural net based on the mnist dataset. We will cover:\n",
        "\n",
        "-MNIST\n",
        "-DataLoader and Transformation\n",
        "\n",
        "-Multilayer Neural Net, activation Function\n",
        "\n",
        "-Loss and Optimizer\n",
        "\n",
        "-Training Loop (batch training)\n",
        "\n",
        "-Model evaluation\n",
        "\n",
        "-GPU support"
      ],
      "metadata": {
        "id": "3-FdvSc_x2TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the relevant libraries:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision #for datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eeXcvs6FPKO6"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device configurations if we have a gpu, will guarantee that tensors will be pushed to gpu if we have it\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "zLjKixgXP1N1"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define some hyperparameters\n",
        "input_size=784 #as img size is 28*28 =784, need to flatten them as a 1d tensor\n",
        "hidden_size=100\n",
        "num_classes=10 #digits from 0 to 9\n",
        "num_epochs=2\n",
        "batch_size=100\n",
        "learning_rate=0.001"
      ],
      "metadata": {
        "id": "C7URFSJdQ9pG"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the MNIST data:\n",
        "train_dataset=torchvision.datasets.MNIST(root=\"./data\", train=True,\n",
        "                                         transform= transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "NM8uoA2wQ_PM"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#do the same thing for test dataset\n",
        "test_dataset=torchvision.datasets.MNIST(root=\"./data\", train=False,\n",
        "                                         transform= transforms.ToTensor())"
      ],
      "metadata": {
        "id": "iQUZosFmRCmf"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the training and the testing data"
      ],
      "metadata": {
        "id": "9QDy-AJ5QDHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "5nDekmlIRvks"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                        batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "FTy_XPyrR0_5"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#look at a sample of the data\n",
        "examples=iter(train_loader)\n",
        "samples, labels= examples.next()\n",
        "print(samples.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCmdiD44SJ5f",
        "outputId": "ed96c862-6b62-4fe8-b852-a5a780edf4d3"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  plt.subplot(2,3, i+1)\n",
        "  plt.imshow(samples[i][0], cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "vytmNXXrSkh2",
        "outputId": "3544db74-4d78-4c30-d78e-7f98656b4eea"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the classification NN"
      ],
      "metadata": {
        "id": "Mi3QJ_ywTgY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    #create layers\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.l2=nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out=self.l1(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.l2(out)\n",
        "    #don't want softmax, will appy x entropy here that will do the softmax for us\n",
        "    return out"
      ],
      "metadata": {
        "id": "zpKnIL0oTj5N"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "instantiate the nn objects and configure the loss and optimizer functions"
      ],
      "metadata": {
        "id": "vsbLLRPiycZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= NeuralNet(input_size, hidden_size, num_classes)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer= torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "QzcTaOwqX1ll"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the main training loop"
      ],
      "metadata": {
        "id": "-iUWcdLlykBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "n_total_steps=len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    #reshape images 100 28 28\n",
        "    #want to reshape to 784\n",
        "    images=images.reshape(-1,28*28).to(device)#flatten iamge\n",
        "    labels=labels.to(device)#push tensors to gpu\n",
        "\n",
        "    #forward pass:\n",
        "    outputs=model(images)\n",
        "    loss=criterion(outputs,labels)\n",
        "\n",
        "    #backward pass\n",
        "    optimizer.zero_grad() #empty gradients\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    #print info every 100 step\n",
        "    if (i+1)%100 ==0:\n",
        "      print(f\"epoch {epoch + 1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item() :.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTb9KdV1Yt3N",
        "outputId": "f7209c47-c369-4a69-b23a-2f80f97fa65f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/2, step 100/600, loss = 0.440\n",
            "epoch 1/2, step 200/600, loss = 0.382\n",
            "epoch 1/2, step 300/600, loss = 0.197\n",
            "epoch 1/2, step 400/600, loss = 0.150\n",
            "epoch 1/2, step 500/600, loss = 0.114\n",
            "epoch 1/2, step 600/600, loss = 0.328\n",
            "epoch 2/2, step 100/600, loss = 0.154\n",
            "epoch 2/2, step 200/600, loss = 0.125\n",
            "epoch 2/2, step 300/600, loss = 0.173\n",
            "epoch 2/2, step 400/600, loss = 0.161\n",
            "epoch 2/2, step 500/600, loss = 0.205\n",
            "epoch 2/2, step 600/600, loss = 0.151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test the model"
      ],
      "metadata": {
        "id": "yz4gR1qwynbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "with torch.no_grad():\n",
        "  n_correct=0\n",
        "  n_samples=0\n",
        "  for images, labels in test_loader:\n",
        "    #reshape images like before and push to device\n",
        "    images=images.reshape(-1,28*28).to(device)#flatten iamge\n",
        "    labels=labels.to(device)#push tensors to gp\n",
        "    outputs=model(images)\n",
        "\n",
        "    _, predictions = torch.max(outputs, 1) #returns the value and index (class label)\n",
        "    n_samples= labels.shape[0] #no of samples in current batch should be 100\n",
        "    n_correct = (predictions == labels).sum().item()\n",
        "\n",
        "  acucracy=100.0* n_correct/n_samples\n",
        "  print(f\"accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9XVAxrQyqAP",
        "outputId": "b9e9a525-558b-4357-c5ce-93d3c1d93adb"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9035087823867798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0M5d07EGSYFb"
      }
    }
  ]
}