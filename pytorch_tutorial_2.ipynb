{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAeyi6zpMEgpC10wnakSb0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Beatrix-droid/pytorch-tutorial/blob/master/pytorch_tutorial_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g92CDjjRqU_m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Learning Pytorch\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "P8a5TFKLqWL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating a tensor"
      ],
      "metadata": {
        "id": "rGhh2mcZwC6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a tensor:\n",
        "import torch\n",
        "\n",
        "x = torch.empty(2,2) # a 2d tensor\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfaHP0_brG9x",
        "outputId": "531668bc-ef33-4360-ee37-d0d4d3b47e2e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0729e-35, 0.0000e+00],\n",
            "        [3.3631e-44, 0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "can sue teh rand ne==method to create a tensor with random numbers"
      ],
      "metadata": {
        "id": "I03pJgRLryX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#can create tensors from lists as well:\n",
        "torch.tensor([[1., -1.], [1., -1.]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGhuMhg-sJIi",
        "outputId": "c796d147-b035-4426-f84d-8056aad355f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1., -1.],\n",
              "        [ 1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#can add tensors as you would normal add ints or concat strings\n",
        "\n",
        "#can also add one tensor to another:\n",
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "y.add_(x) #add tensor x to y. By defualt any function with a trailing underscore in pytorch will be an inplace operation\n",
        "\n",
        "\n",
        "#can also divide and multiplu as one normally woukld"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP8Z-L9ZsRD9",
        "outputId": "fbce059a-0e4d-456e-8163-aea0f6ae6ae6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5539, 1.3596],\n",
              "        [1.3558, 0.5506]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting a tensor to a numpy array"
      ],
      "metadata": {
        "id": "LotxgwlNwJs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a=torch.ones(5) #a 1d tensor of len 5 full of ones\n",
        "b = a.numpy() #conver to array\n",
        "print(a)\n",
        "print(type(b))\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgpZNMjRwOm_",
        "outputId": "ccae2e0d-3fa6-4ca2-be06-16915b8dbfe4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'numpy.ndarray'>\n",
            "[1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting an array to a tensor"
      ],
      "metadata": {
        "id": "ry9L9Zcxxg54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.ones(5) #instantiate the array\n",
        "b=torch.from_numpy(a) #convert the arary to a pytorch tensor\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IocdHmXwk91",
        "outputId": "3ed71f17-a3e9-40d4-f06f-df38c0586e73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if you have a cuda toolkit avaialble to do operations on the gpu"
      ],
      "metadata": {
        "id": "FHEe8ZCPyJo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  x= torch.ones(5, device=device)\n",
        "  y=torch.ones(5)\n",
        "  y=y.to(device) #create and move tensors to gpu\n",
        "#if you now try to use numpy n calling  \n",
        "  x.numpy()\n",
        "  #you will get an error because numpy can only handle \n",
        "  #cpu tensors so we would have to move it back to the cpu\n",
        "  x=x.to('cpu')\n",
        "  "
      ],
      "metadata": {
        "id": "W8FYCCUvx01w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad = true\n",
        "when creatinga  tensor in pytorch we can set an optional parameter to True: requires_grad=True  This tells pytorch that it will have to calculate teh gradient of the tensor later on in the computation"
      ],
      "metadata": {
        "id": "WUV-0rbK8BJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad=True)"
      ],
      "metadata": {
        "id": "ADC_dx748AZF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd Pytorch\n",
        "calculate gradients to optimize models"
      ],
      "metadata": {
        "id": "nm_zmOaX8kXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m-mynKU8eIt",
        "outputId": "40cf851b-fe3a-4a8b-af8f-f84f9224930b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3228, 0.8454, 0.5747])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#say we need ot calculate the gradient of a functionat that point.\n",
        "#we set requires_grad=True:\n",
        "x = torch.rand(3, requires_grad=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "b3O_4uRN80k-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now do an operation:\n",
        "y = x+2\n",
        "print(y) #operation was addition so the grad_funct was add\n",
        "z = y*y*2\n",
        "print(z)#operation was mult so the grad_funct was mult\n",
        "z=z.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x_Gxm149QTr",
        "outputId": "de1a8a1a-9dfe-461e-f19f-034d513fd797"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.3048, 2.2649, 2.5465], grad_fn=<AddBackward0>)\n",
            "tensor([10.6244, 10.2591, 12.9688], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now when we want to calculate the gradients the only thing that we need to do is call the .backward() method:"
      ],
      "metadata": {
        "id": "Au3fCgqo_b6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()# will calculate the gradient of z with respect to x so dz/dx"
      ],
      "metadata": {
        "id": "W6OtYGtN_acZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now x has a grad attribute with teh gradients stored that we can use:\n",
        "\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aObXBxBM_v8_",
        "outputId": "977970ea-de5a-4688-bea0-c2cad2c6e57c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.0731, 3.0198, 3.3953])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case z was a scalar (as z =z.mean()) so we could just implciitly call the backward function on it.\n",
        "\n",
        "the backward function is based on the chain rule  (jacobain matrix)(vector) = (gradients we are interested in\n",
        "![image info](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "914eY5SIAxq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "in general if z is a vector you need to pass the value f the vector in the function.Say we had something like:\n",
        "```\n",
        "v= torch.tensor([0.1. 1.0, 0.001],dtype=torch.float32)\n",
        "z = y*y*2 #z is now a bector\n",
        "z.backward(v)\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9iJV-1EjAxw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preventing Pytorch from tracking the history\n",
        " (useful when updating weights of a model)\n",
        "\n",
        " We have three options on how to do this:\n",
        " \n",
        " ```\n",
        " 1) x.requres_grad_(False)\n",
        " 2) x.detach()\n",
        " 3) with torch.no_grad():\n",
        " ```"
      ],
      "metadata": {
        "id": "ukH0fUSADq5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#method 1\n",
        "x.requires_grad_(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsV4YrHpDqFf",
        "outputId": "2062fa29-32cb-4d0f-9f62-fba1f653795d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3048, 0.2649, 0.5465])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method 2\n",
        "y = x.detach() #creates a new tensor with teh same values but no gradient\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQocqZlWEZyf",
        "outputId": "5c32ca6c-3c66-4e12-b8e2-7351a97529ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3048, 0.2649, 0.5465])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#method 3\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EckgFxwGEjYH",
        "outputId": "50330de8-4dbe-4de6-99c6-00ba04b6741e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.3048, 2.2649, 2.5465])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "warning, whenever we call the backward  function then the gradient for the tensors will be accumulated and summed up in the .grad attribute:"
      ],
      "metadata": {
        "id": "9Rywk4QOE3vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(2):\n",
        "  model_output= (weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK9H59LPEyl_",
        "outputId": "3b71a520-fa5d-42e0-feb6-3dfb74c88f98"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for the second one the gradients are incorrect. they have neen usmmed up hence 6\n",
        "\n",
        "#must clear the weights each time:\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "for epoch in range(2):\n",
        "  model_output= (weights*3).sum()\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()#this is the important line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZXELvTMFsKz",
        "outputId": "aeeeac7b-27da-4420-8c1a-07695e530f7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Descent and constructing a basic pipeline for pytorch\n",
        "let's see how to optimize paarameters from scracth by using a linear regression model that we will code from scratch"
      ],
      "metadata": {
        "id": "oCKBegWqvmJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f = w+x\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X=np.array([1,2,3,4], dtype=np.float32)\n",
        "Y=np.array([2,4,6,8], dtype=np.float32)\n",
        "\n",
        "w=0.0"
      ],
      "metadata": {
        "id": "QMNkbEOCvtIi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "\n",
        "#least square residual loss function\n",
        "def loss(y, y_predicted):\n",
        "  return((y_predicted -y)**2).mean()\n",
        "\n",
        "#gradient\n",
        "#MSE = 1/n *(wx-y)^2 formual for mean squared error\n",
        "#dj/dw = 1/N 2x(wx-y)\n",
        "#implement this fromulka in the gradient: y_predicted= y_predicted\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean() #mean as dividing by n in formula\n"
      ],
      "metadata": {
        "id": "IArJMoQK11q7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"prediction before training: f(5)={forward(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAS6FC1T18KA",
        "outputId": "b600d1a0-b637-45ee-b240-50317a845de1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: f(5)=0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters=10\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  dw=gradient(X,Y, y_pred)\n",
        "\n",
        "  #update weights\n",
        "  w=w-learning_rate *dw\n",
        "\n",
        "  if epoch % 1 ==0:\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={forward(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0ZNcURJ2L_b",
        "outputId": "8fa6a9d3-4f7a-4fa6-8202-96b2213d7362"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: W=1.2, loss = 30.0\n",
            "prediction after trainingf(5)=6.0\n",
            "epoch 2: W=1.6799999618530272, loss = 4.799999237060547\n",
            "prediction after trainingf(5)=8.399999809265136\n",
            "epoch 3: W=1.871999988555908, loss = 0.7680001854896545\n",
            "prediction after trainingf(5)=9.35999994277954\n",
            "epoch 4: W=1.9487999868392942, loss = 0.1228799968957901\n",
            "prediction after trainingf(5)=9.743999934196472\n",
            "epoch 5: W=1.9795200133323667, loss = 0.019660834223031998\n",
            "prediction after trainingf(5)=9.897600066661834\n",
            "epoch 6: W=1.9918080282211301, loss = 0.0031457357108592987\n",
            "prediction after trainingf(5)=9.95904014110565\n",
            "epoch 7: W=1.9967231869697568, loss = 0.0005033080233260989\n",
            "prediction after trainingf(5)=9.983615934848784\n",
            "epoch 8: W=1.99868928194046, loss = 8.053186320466921e-05\n",
            "prediction after trainingf(5)=9.993446409702301\n",
            "epoch 9: W=1.999475698471069, loss = 1.2884394891443662e-05\n",
            "prediction after trainingf(5)=9.997378492355345\n",
            "epoch 10: W=1.999790253639221, loss = 2.0613531432900345e-06\n",
            "prediction after trainingf(5)=9.998951268196105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we did the computation of weights manually\n",
        "now lets do the same thing with pytorch. No need for numpy arrays, will use Pytorch tensors"
      ],
      "metadata": {
        "id": "770Ff1_y5QWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X=torch.tensor([1,2,3,4], dtype=torch.float32, requires_grad=True)\n",
        "Y=torch.tensor([2,4,6,8], dtype=torch.float32,  requires_grad=True)\n",
        "w=torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
      ],
      "metadata": {
        "id": "donc5Z5_5MjF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "\n",
        "#least square residual loss function\n",
        "def loss(y, y_predicted):\n",
        "  return((y_predicted -y)**2).mean()\n",
        "\n",
        "#gradient\n",
        "#MSE = 1/n *(wx-y)^2 formual for mean squared error\n",
        "#dj/dw = 1/N 2x(wx-y)\n",
        "#implement this fromulka in the gradient: y_predicted= y_predicted\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean() #mean as dividing by n in formula"
      ],
      "metadata": {
        "id": "cwLWO-sG5rkV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w-= learning_rate * w.grad\n",
        "\n",
        "  w.grad.zero_()  \n",
        "  if epoch % 1 ==0:\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={forward(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaL72pHr9Ru4",
        "outputId": "57cf06d3-8cbf-47f7-f1e4-f667ae25639f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: W=0.29999998211860657, loss = 30.0\n",
            "prediction after trainingf(5)=1.4999998807907104\n",
            "epoch 2: W=0.5549999475479126, loss = 21.674999237060547\n",
            "prediction after trainingf(5)=2.7749996185302734\n",
            "epoch 3: W=0.7717499136924744, loss = 15.660187721252441\n",
            "prediction after trainingf(5)=3.8587496280670166\n",
            "epoch 4: W=0.9559874534606934, loss = 11.314486503601074\n",
            "prediction after trainingf(5)=4.779937267303467\n",
            "epoch 5: W=1.1125893592834473, loss = 8.17471694946289\n",
            "prediction after trainingf(5)=5.562946796417236\n",
            "epoch 6: W=1.2457009553909302, loss = 5.9062323570251465\n",
            "prediction after trainingf(5)=6.228504657745361\n",
            "epoch 7: W=1.358845829963684, loss = 4.2672529220581055\n",
            "prediction after trainingf(5)=6.794229030609131\n",
            "epoch 8: W=1.4550189971923828, loss = 3.083089828491211\n",
            "prediction after trainingf(5)=7.275094985961914\n",
            "epoch 9: W=1.5367661714553833, loss = 2.227532148361206\n",
            "prediction after trainingf(5)=7.683830738067627\n",
            "epoch 10: W=1.6062512397766113, loss = 1.609391689300537\n",
            "prediction after trainingf(5)=8.031255722045898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "loss=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD([w], lr=learning_rate)"
      ],
      "metadata": {
        "id": "v-5MOpcz_RtY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "replacing the optimizers and the loss function"
      ],
      "metadata": {
        "id": "na7FL5fwKUTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  if epoch % 1 ==0:\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={forward(5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X55OaDyUChcw",
        "outputId": "51c0d816-6ef2-420f-cfdd-84a0ea9e877e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: W=1.6653136014938354, loss = 1.1627856492996216\n",
            "prediction after trainingf(5)=8.326567649841309\n",
            "epoch 2: W=1.7155165672302246, loss = 0.8401124477386475\n",
            "prediction after trainingf(5)=8.577583312988281\n",
            "epoch 3: W=1.758189082145691, loss = 0.6069811582565308\n",
            "prediction after trainingf(5)=8.790945053100586\n",
            "epoch 4: W=1.7944607734680176, loss = 0.4385439455509186\n",
            "prediction after trainingf(5)=8.97230339050293\n",
            "epoch 5: W=1.825291633605957, loss = 0.3168478012084961\n",
            "prediction after trainingf(5)=9.126458168029785\n",
            "epoch 6: W=1.8514978885650635, loss = 0.22892260551452637\n",
            "prediction after trainingf(5)=9.257489204406738\n",
            "epoch 7: W=1.873773217201233, loss = 0.1653965264558792\n",
            "prediction after trainingf(5)=9.368865966796875\n",
            "epoch 8: W=1.8927072286605835, loss = 0.11949898302555084\n",
            "prediction after trainingf(5)=9.463536262512207\n",
            "epoch 9: W=1.9088011980056763, loss = 0.08633805811405182\n",
            "prediction after trainingf(5)=9.54400634765625\n",
            "epoch 10: W=1.9224810600280762, loss = 0.0623791441321373\n",
            "prediction after trainingf(5)=9.612405776977539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "replacing the forward function"
      ],
      "metadata": {
        "id": "DrIcyLBqKXoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is where we would define the model\n",
        "X=torch.tensor([[1],[2],[3],[4]], dtype=torch.float32, requires_grad=True)\n",
        "Y=torch.tensor([[2],[4],[6],[8]], dtype=torch.float32,  requires_grad=True)\n",
        "X_test= torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "imput_size = n_features\n",
        "output_size = n_features\n",
        "model = nn.Linear(imput_size, output_size)"
      ],
      "metadata": {
        "id": "0Exh-639KMrY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss=nn.MSELoss()\n",
        "#updates the weights\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "PBarsAP9LZZ1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  if epoch % 1 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={model(X_test).item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjVn3fNuLur0",
        "outputId": "14a28380-0217-4e94-9003-3ede162d7303"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1: W=Parameter containing:\n",
            "tensor([[0.4375]], requires_grad=True), loss = 0.0450688973069191\n",
            "prediction after trainingf(5)=2.5820541381835938\n",
            "epoch 2: W=Parameter containing:\n",
            "tensor([[0.6719]], requires_grad=True), loss = 18.310523986816406\n",
            "prediction after trainingf(5)=3.7539281845092773\n",
            "epoch 3: W=Parameter containing:\n",
            "tensor([[0.8711]], requires_grad=True), loss = 13.229354858398438\n",
            "prediction after trainingf(5)=4.750021457672119\n",
            "epoch 4: W=Parameter containing:\n",
            "tensor([[1.0404]], requires_grad=True), loss = 9.558207511901855\n",
            "prediction after trainingf(5)=5.596700191497803\n",
            "epoch 5: W=Parameter containing:\n",
            "tensor([[1.1844]], requires_grad=True), loss = 6.905806541442871\n",
            "prediction after trainingf(5)=6.316377639770508\n",
            "epoch 6: W=Parameter containing:\n",
            "tensor([[1.3067]], requires_grad=True), loss = 4.989445686340332\n",
            "prediction after trainingf(5)=6.928103446960449\n",
            "epoch 7: W=Parameter containing:\n",
            "tensor([[1.4107]], requires_grad=True), loss = 3.6048736572265625\n",
            "prediction after trainingf(5)=7.448070526123047\n",
            "epoch 8: W=Parameter containing:\n",
            "tensor([[1.4991]], requires_grad=True), loss = 2.6045210361480713\n",
            "prediction after trainingf(5)=7.890042781829834\n",
            "epoch 9: W=Parameter containing:\n",
            "tensor([[1.5742]], requires_grad=True), loss = 1.8817662000656128\n",
            "prediction after trainingf(5)=8.265719413757324\n",
            "epoch 10: W=Parameter containing:\n",
            "tensor([[1.6381]], requires_grad=True), loss = 1.3595759868621826\n",
            "prediction after trainingf(5)=8.585043907165527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "template for creating our custom linear regression model:\n"
      ],
      "metadata": {
        "id": "ixis9skNMTC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  \n",
        "  def __init__(self, imput_dim, ouptut_dim):\n",
        "    super(LinearRegression,self).__init__()\n",
        "    #define layers:\n",
        "    self.lin= nn.Linear(imput_dim, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "YXjEDb5KMShr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instantiating an instance of the model:\n",
        "model=LinearRegression(imput_size,output_size)\n",
        "print(f\"Prediction before training f(5)={model(X_test).item()}\")\n",
        "for epoch in range(n_iters):\n",
        "  \n",
        "  #prediction\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradient\n",
        "  l.backward() #dl/dw\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  if epoch % 1 ==0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f\"epoch {epoch+1}: W={w}, loss = {l}\")\n",
        "  print(f\"prediction after trainingf(5)={model(X_test).item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAMJ-KztNEqr",
        "outputId": "f245852a-ef52-4f57-d65c-8c2c9064db6e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training f(5)=-4.584939002990723\n",
            "epoch 1: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 0.9822933673858643\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 2: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 3: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 4: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 5: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 6: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 7: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 8: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 9: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n",
            "epoch 10: W=Parameter containing:\n",
            "tensor([[-0.8905]], requires_grad=True), loss = 62.66228103637695\n",
            "prediction after trainingf(5)=-4.584939002990723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression in Pytorch"
      ],
      "metadata": {
        "id": "6erKBKjXOa83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typical pytorch pipeline\n",
        "\n",
        "1) design model (input, output size,    forward pass)\n",
        "\n",
        "2) construct loss and optimizer\n",
        "\n",
        "3)training loop\n",
        "\n",
        "4)forward pass: compute prediction and loss\n",
        "\n",
        "5)backward pass: gradients\n",
        "\n",
        "6)update weights\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YsRgH0p7mSnD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's look at a more concrete examplem of this:"
      ],
      "metadata": {
        "id": "dZqSQ0G5nJb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "egu17z23mzAF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare data:\n",
        "X_numpy, y_numpy= datasets.make_regression(n_samples=100, n_features=1, \n",
        "                                           noise=20, random_state=1)\n",
        "\n",
        "X=torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y=torch.from_numpy(y_numpy.astype(np.float32))\n",
        "\n",
        "#reshape the tensor:\n",
        "y=y.view(y.shape[0], 1)"
      ],
      "metadata": {
        "id": "bqfYnvBsnRYC"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now that we have preprocessed the data we can proceed with our three steps:\n",
        "\n",
        "     1)step1: design the model"
      ],
      "metadata": {
        "id": "bxoh4FG2oHdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=n_features\n",
        "output_size=1\n",
        "model = nn.Linear(input_size, output_size)"
      ],
      "metadata": {
        "id": "On0GkHN4notK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: define the loss and optimizer functions:"
      ],
      "metadata": {
        "id": "PxPFkiSrozn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=0.01\n",
        "criterion=nn.MSELoss()#in case of linear regression use mean square error function for loss\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "TV2Rf_bpo4Y6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: make the training loop:"
      ],
      "metadata": {
        "id": "DNffD942pXay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass\n",
        "  y_predicted = model(X)\n",
        "  loss=criterion(y_predicted, y)\n",
        "\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  optimizer.step()\n",
        "\n",
        "  #empty gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #print some info every tenth epoch\n",
        "  if (epoch +1)%10 ==0:\n",
        "    print(f\"epoch: {epoch + 1}, loss= {loss.item():.3f}\") #cut at 3 decimal values\n",
        "  \n",
        "\n",
        "#plot values:\n",
        "predicted=model(X).detach().numpy() #must detach as this tensor has gradients set to true\n",
        "plt.plot(X_numpy, y_numpy, \"ro\")\n",
        "plt.plot(X_numpy, predicted,\"b\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "FbW0BdulpcRV",
        "outputId": "670f9d63-3784-485b-8edc-b62d61ee7a22"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss= 4343.990\n",
            "epoch: 20, loss= 3241.624\n",
            "epoch: 30, loss= 2444.091\n",
            "epoch: 40, loss= 1866.476\n",
            "epoch: 50, loss= 1447.720\n",
            "epoch: 60, loss= 1143.853\n",
            "epoch: 70, loss= 923.167\n",
            "epoch: 80, loss= 762.766\n",
            "epoch: 90, loss= 646.098\n",
            "epoch: 100, loss= 561.183\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic regression\n",
        "\n",
        "this is an example of a logistic regression model in pytorch"
      ],
      "metadata": {
        "id": "0APh2YNzpXiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "step 1) load and prerpare the data"
      ],
      "metadata": {
        "id": "HSfh5m8PxOP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "iEL8xEm9xIHh"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer=datasets.load_breast_cancer()\n",
        "X,y=breast_cancer.data,breast_cancer.target"
      ],
      "metadata": {
        "id": "2SBQkId6xcFx"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_sampless, n_features=X.shape\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "w37e7EFHxsjC"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scale data\n",
        "sc = StandardScaler()\n",
        "X_train =sc.fit_transform(X_train)\n",
        "X_test =sc.fit_transform(X_test)\n",
        "\n",
        "# convert to torch tensors:\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))"
      ],
      "metadata": {
        "id": "V3Yy_JkvyBep"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape y\n",
        "y_train = y_train.view(y_train.shape[0],1) #want to make y into a column, vector\n",
        "y_test =y_test.view(y_test.shape[0],1)"
      ],
      "metadata": {
        "id": "3DlToGmCywya"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prepare the model using the logistic regression function"
      ],
      "metadata": {
        "id": "wajD3L4OzHkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "\n",
        "  def __init__(self,input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear=nn.Linear(input_features,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "#instantiate an instance of the model\n",
        "model=LogisticRegression(n_features)"
      ],
      "metadata": {
        "id": "HVBHNmBozM-b"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define optimizer and loss functions"
      ],
      "metadata": {
        "id": "rXDishpg2i1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss() #binary cross entropy\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "hDNsBLCN2Mjp"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main training loop:"
      ],
      "metadata": {
        "id": "QJwGKd6N25FL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass\n",
        "  y_predicted=model(X_train)\n",
        "  loss=criterion(y_predicted,y_train)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  #empty weights\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #print info:\n",
        "  if (epoch + 1) %10 ==0:\n",
        "    print(f\"epoch: {epoch + 1}, loss= {loss.item():.3f}\") #cut at 3 decimal values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwr6E56S27fe",
        "outputId": "54cd696b-d08d-49f1-a3f1-f6408f03cb56"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss= 0.691\n",
            "epoch: 20, loss= 0.539\n",
            "epoch: 30, loss= 0.451\n",
            "epoch: 40, loss= 0.394\n",
            "epoch: 50, loss= 0.354\n",
            "epoch: 60, loss= 0.324\n",
            "epoch: 70, loss= 0.300\n",
            "epoch: 80, loss= 0.281\n",
            "epoch: 90, loss= 0.266\n",
            "epoch: 100, loss= 0.252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate performance of model"
      ],
      "metadata": {
        "id": "iKzRGCPC4HcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()\n",
        "  accuracy=y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
        "  print(f'accuracy: {accuracy: .3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WIaOlOz38me",
        "outputId": "13a9d839-2078-48d6-8651-ac2d5c304400"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch Datatests and DataLoader Classes\n",
        "\n",
        "going over some terminology: \n",
        "\n",
        "epoch: 1 forward and backward pass of ALL training samples\n",
        "\n",
        "batch_size: number of training samples in one forward and backward pass\n",
        "\n",
        "number of iterations: number of apsses, each pass using [batch_size] number of samples\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2xt_RYsS57P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import needed modules\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n"
      ],
      "metadata": {
        "id": "_PESv2aO48oM"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "start implementing our own custom dataset:"
      ],
      "metadata": {
        "id": "Hl-q3gsH7TTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy=np.loadtxt('https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv', \n",
        "                  delimiter=',',dtype=np.float32, skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:,1:])\n",
        "    self.y=torch.from_numpy(xy[:,[0]]) #n_samples, 1\n",
        "    self.n_samples =xy.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #allows you to get data by the index\n",
        "    #dataset[0]\n",
        "    return self.x[index], self.y[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    #get len of dataset\n",
        "    return self.n_samples\n",
        "  "
      ],
      "metadata": {
        "id": "Az7oQyvE7W8a"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get dataset:\n",
        "dataset=WineDataset()\n",
        "first_data=dataset[0]\n",
        "features, labels=first_data\n",
        "print(features,labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvk7pEjP-GTs",
        "outputId": "da0b39b8-e6b2-47c6-94bf-9dc3cd06e92f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is how we get a dataset. Now let's see how we use a dataloader"
      ],
      "metadata": {
        "id": "7fjViytyA3-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "3EbTz_ZsA3Ir"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter=iter(dataloader)\n",
        "data = dataiter.next()\n",
        "features,labels=data\n",
        "print(features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry-PrdjAAmdD",
        "outputId": "7fc47f3d-f528-40e6-a7ce-f6c40c36807b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2880e+01, 2.9900e+00, 2.4000e+00, 2.0000e+01, 1.0400e+02, 1.3000e+00,\n",
            "         1.2200e+00, 2.4000e-01, 8.3000e-01, 5.4000e+00, 7.4000e-01, 1.4200e+00,\n",
            "         5.3000e+02],\n",
            "        [1.4060e+01, 1.6300e+00, 2.2800e+00, 1.6000e+01, 1.2600e+02, 3.0000e+00,\n",
            "         3.1700e+00, 2.4000e-01, 2.1000e+00, 5.6500e+00, 1.0900e+00, 3.7100e+00,\n",
            "         7.8000e+02],\n",
            "        [1.2200e+01, 3.0300e+00, 2.3200e+00, 1.9000e+01, 9.6000e+01, 1.2500e+00,\n",
            "         4.9000e-01, 4.0000e-01, 7.3000e-01, 5.5000e+00, 6.6000e-01, 1.8300e+00,\n",
            "         5.1000e+02],\n",
            "        [1.3360e+01, 2.5600e+00, 2.3500e+00, 2.0000e+01, 8.9000e+01, 1.4000e+00,\n",
            "         5.0000e-01, 3.7000e-01, 6.4000e-01, 5.6000e+00, 7.0000e-01, 2.4700e+00,\n",
            "         7.8000e+02]]) tensor([[3.],\n",
            "        [1.],\n",
            "        [3.],\n",
            "        [3.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#iterate over whole data loader\n",
        "#training loop:\n",
        "num_epochs=2\n",
        "total_samples=len(dataset)\n",
        "n_iterations= math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmdP8qoIBUos",
        "outputId": "ebd205cb-f3f4-41ad-8aa1-2e4544ec3246"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dummy training loop:\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, labels) in enumerate(dataloader):\n",
        "    #forward and backward pass, update weights\n",
        "    if (i+1)%5 ==0:\n",
        "      print(f\"epoch {epoch+1}/{num_epochs}, step{i+1}/{n_iterations},inputs={inputs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrnVTpETF5aK",
        "outputId": "9b547851-8ea0-447a-f36e-0bc79c0250cb"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/2, step5/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step10/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step15/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step20/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step25/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step30/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step35/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step40/45,inputs=torch.Size([4, 13])\n",
            "epoch 1/2, step45/45,inputs=torch.Size([2, 13])\n",
            "epoch 2/2, step5/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step10/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step15/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step20/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step25/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step30/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step35/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step40/45,inputs=torch.Size([4, 13])\n",
            "epoch 2/2, step45/45,inputs=torch.Size([2, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Transforms!\n",
        "\n",
        "we will see how to write a custom class to transform our data\n",
        "\n",
        "Gathering data and code from the previous section, we can skip transforming X and Y in tensors and write separate methods especially for that:\n",
        "\n"
      ],
      "metadata": {
        "id": "k6PY_iURH-aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToTensor:\n",
        "\n",
        "  \"\"\"A class that handles data transformations into tensors\"\"\"\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    \"\"\"This special dunder method makes this a callable object\"\"\"\n",
        "    inputs,targets=sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "aO7QIvfEG7eO"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We need to modify the dataclass to use this transform class.\n",
        "\n",
        "To do this, add a parameter \"transform\" in its init method and eliminate the .from_numpy method:\n"
      ],
      "metadata": {
        "id": "OxWyhVOQLODb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self, transform=None):#added transform parameter\n",
        "    #data loading\n",
        "    xy=np.loadtxt('https://raw.githubusercontent.com/python-engineer/pytorchTutorial/master/data/wine/wine.csv', \n",
        "                  delimiter=',',dtype=np.float32, skiprows=1)\n",
        "    self.x = xy[:,1:]#modified here\n",
        "    self.y=xy[:,[0]] # and here n_samples, 1\n",
        "    self.n_samples =xy.shape[0]\n",
        "    self.transform=transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #allows you to get data by the index\n",
        "    #dataset[0]\n",
        "    sample=self.x[index], self.y[index] #apply the transformation\n",
        "    if self.transform:\n",
        "      sample=self.transform(sample)\n",
        "      return sample\n",
        "  \n",
        "  def __len__(self):\n",
        "    #get len of dataset\n",
        "    return self.n_samples\n",
        "  "
      ],
      "metadata": {
        "id": "uJOoltslLjZr"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply this transoformation to our dataset\n",
        "dataset = WineDataset(transform=ToTensor())"
      ],
      "metadata": {
        "id": "cNBNs3QMKEMk"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_data=dataset[0]\n",
        "features, labels=first_data\n",
        "print(type(features), type(labels)) #data has been transformed into a tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPUqb_19KKDu",
        "outputId": "344bab58-b1f9-4638-8897-3e49667a7a56"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = WineDataset(transform=None)\n",
        "first_data=dataset[0]\n",
        "features, labels=first_data\n",
        "print(type(features), type(labels))#if we don't pass this optional parameter our data is still in the shape of a numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "vRu19mOrMtwv",
        "outputId": "4419ec51-90f8-40ec-e75d-cfe015bdb2a3"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-c889f6fb897b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfirst_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#if we don't pass this optional parameter our data is still in the shape of a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets try implementing a new class:\n"
      ],
      "metadata": {
        "id": "EFZtelFnNZs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MulTransform:\n",
        "  \"\"\"Multiplication transform\"\"\"\n",
        "\n",
        "  def __init__(self, factor):\n",
        "    self.factor=factor\n",
        "\n",
        "  \n",
        "  def __call__(self, sample):\n",
        "    \"\"\"This special dunder method makes this a callable object\"\"\"\n",
        "    inputs,target=sample\n",
        "    inputs *= self.factor #multiplication transform\n",
        "    return inputs, target\n",
        "    "
      ],
      "metadata": {
        "id": "k-rWeO8eNJXC"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply this new transform\n",
        "\n",
        "\n",
        "#compose to transforms together by using the compose method and putting them into a list\n",
        "composed= torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "\n",
        "first_data=dataset[0]\n",
        "features, labels=first_data\n",
        "print(type(features), type(labels))\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjtMQhqFOB6b",
        "outputId": "dacc2c3f-e4fc-4466-f4e5-f8c928147475"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Softmax and crossentropy"
      ],
      "metadata": {
        "id": "tfEC0lvWPp1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "useful concept to preproces images, like turning them into gray scale and preprocessing them"
      ],
      "metadata": {
        "id": "rwno20VKO9Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "\n",
        "x=np.array([2.0,1.0, 0.1])\n",
        "outputs=softmax(x)\n",
        "print('softmax  numpy', outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g1WMe2yOrN2",
        "outputId": "8f46b87c-3b03-4213-f774-226ad9746c00"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax  numpy [0.65900114 0.24243297 0.09856589]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs=torch.softmax(x, dim=0)\n",
        "print(outputs)#reuslt is almost the same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkRWOpaGUCXq",
        "outputId": "74338df9-ccb8-4748-d159-85e46ec9c5d6"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6590, 0.2424, 0.0986])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy(actual, predicted):\n",
        "  loss=-np.sum(actual * np.log(predicted))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "W278yaLlVxM3"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y must be one hot encoded\n",
        "y=np.array([1,0,0])\n",
        "\n",
        "Y_pred_good=np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad=np.array([0.1, 0.3, 0.6])\n",
        "l1=cross_entropy(y, Y_pred_good)\n",
        "l2=cross_entropy(y, Y_pred_bad)\n",
        "print(f\"Loss1 numpy:{l1: 4f}\")\n",
        "print(f\"Loss2 numpy:{l2: 4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hznZeqt8We72",
        "outputId": "c2363d8b-8909-4085-f776-83709625ec25"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss1 numpy: 0.356675\n",
            "Loss2 numpy: 2.302585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets see how we can do this in pytorch"
      ],
      "metadata": {
        "id": "TIEyEA5jnBrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss=nn.CrossEntropyLoss()\n",
        "#Y no softmax in last layer, y_class has labels so no One hot encode!\n",
        "#Y_pred has raw scores (logits) no softmax!"
      ],
      "metadata": {
        "id": "4Jv16FnTnEWl"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y=torch.tensor([0])\n",
        "#n samples x nlcasses\n",
        "Y_pred_good=torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad=torch.tensor([[0.5, 3.0, 0.3]])"
      ],
      "metadata": {
        "id": "Rf8dbekPrcDJ"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1=loss(Y_pred_good,Y)\n",
        "l2=loss(Y_pred_bad,Y)"
      ],
      "metadata": {
        "id": "ri2buiSjsIMC"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(l1.item(), l2.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roFHK2GlsU7v",
        "outputId": "44a52462-c264-48b0-c1b7-2543aff89756"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4170299470424652 2.6391448974609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_,predictions1=torch.max(Y_pred_good,1)\n",
        "_,predictions2=torch.max(Y_pred_bad,1)\n",
        "print(predictions1, predictions2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMOc7Eu8sXVk",
        "outputId": "9513e81b-ea1e-4652-dcd9-8c473c8bfe10"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0]) tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "simple template on how to create an image classifier model with crossentropy:"
      ],
      "metadata": {
        "id": "JwLdROz4t3Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiclass problems:\n",
        "class NeuralNet2(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet2, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2=nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out=self.linear(x)\n",
        "    out=self.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    #no softmax at the end\n",
        "    return out\n",
        "\n",
        "model=NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion=nn.CrossEntropyLoss() #applies softmax"
      ],
      "metadata": {
        "id": "oW_BwKJtt_jG"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation functions in Pytorch"
      ],
      "metadata": {
        "id": "gRGqUbeRwIqU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V8pg4C09vCuV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}